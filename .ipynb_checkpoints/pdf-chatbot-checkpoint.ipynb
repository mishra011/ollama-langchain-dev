{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e35c44-3734-47a2-92be-6ea8eb425479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary packages\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd0915e-2a6b-418a-83c3-10cb329c4b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will load the PDF file\n",
    "def load_pdf_data(file_path):\n",
    "    # Creating a PyMuPDFLoader object with file_path\n",
    "    loader = PyMuPDFLoader(file_path=file_path)\n",
    "    \n",
    "    # loading the PDF file\n",
    "    docs = loader.load()\n",
    "    \n",
    "    # returning the loaded document\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16cd1824-4a4c-4d09-bec3-5e23e834c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Responsible for splitting the documents into several chunks\n",
    "def split_docs(documents, chunk_size=1000, chunk_overlap=20):\n",
    "    \n",
    "    # Initializing the RecursiveCharacterTextSplitter with\n",
    "    # chunk_size and chunk_overlap\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    \n",
    "    # Splitting the documents into chunks\n",
    "    chunks = text_splitter.split_documents(documents=documents)\n",
    "    \n",
    "    # returning the document chunks\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae1b51f-cef8-489a-8781-04ac04cc9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading the embedding model\n",
    "def load_embedding_model(model_path, normalize_embedding=True):\n",
    "    return HuggingFaceEmbeddings(\n",
    "        model_name=model_path,\n",
    "        model_kwargs={'device':'cpu'}, # here we will run the model with CPU only\n",
    "        encode_kwargs = {\n",
    "            'normalize_embeddings': normalize_embedding # keep True to compute cosine similarity\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# Function for creating embeddings using FAISS\n",
    "def create_embeddings(chunks, embedding_model, storing_path=\"vectorstore\"):\n",
    "    # Creating the embeddings using FAISS\n",
    "    vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
    "    \n",
    "    # Saving the model in current directory\n",
    "    vectorstore.save_local(storing_path)\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9362a59-04fd-450e-88cd-d329cdd9e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "### System:\n",
    "You are an AI Assistant that follows instructions extreamly well. \\\n",
    "Help as much as you can.\n",
    "\n",
    "### User:\n",
    "{prompt}\n",
    "\n",
    "### Response:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56657b34-737a-4e61-b9c4-e399c262d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "### System:\n",
    "You are an respectful and honest assistant. You have to answer the user's \\\n",
    "questions using only the context provided to you. If you don't know the answer, \\\n",
    "just say you don't know. Don't try to make up an answer.\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### User:\n",
    "{question}\n",
    "\n",
    "### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba1d1fcc-ec68-42d7-915f-210039e70a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the chain for Question Answering\n",
    "def load_qa_chain(retriever, llm, prompt):\n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever, # here we are using the vectorstore as a retriever\n",
    "        chain_type=\"stuff\",\n",
    "        return_source_documents=True, # including source documents in output\n",
    "        chain_type_kwargs={'prompt': prompt} # customizing the prompt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff74cdfc-0dfe-45e1-a134-589a665dbb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prettifying the response\n",
    "def get_response(query, chain):\n",
    "    # Getting response from chain\n",
    "    response = chain({'query': query})\n",
    "    \n",
    "    # Wrapping the text for better output in Jupyter Notebook\n",
    "    wrapped_text = textwrap.fill(response['result'], width=100)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf43eef-9a99-4896-929b-835dc060ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from lang_funcs import *\n",
    "from langchain.llms import Ollama\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47bbefde-a6aa-4da0-8de5-fd31aabf1b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loading orca-mini from Ollama\n",
    "llm = Ollama(model=\"llama3\", temperature=0)\n",
    "\n",
    "# Loading the Embedding Model\n",
    "embed = load_embedding_model(model_path=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "172df11d-b32d-42e8-bfba-97292038a987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/transformers/utils/import_utils.py:653: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/transformers/modeling_attn_mask_utils.py:448: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  or (hasattr(torch, \"_dynamo\") and torch._dynamo.is_compiling())\n"
     ]
    }
   ],
   "source": [
    "# loading and splitting the documents\n",
    "docs = load_pdf_data(file_path=\"Dee Learning Crash Course For Beginners _240611_180111.pdf\")\n",
    "documents = split_docs(documents=docs)\n",
    "\n",
    "# creating vectorstore\n",
    "vectorstore = create_embeddings(documents, embed)\n",
    "\n",
    "# converting vectorstore to a retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d20deea-6549-4c9c-815f-c51da6e15e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the prompt from the template which we created before\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Creating the chain\n",
    "chain = load_qa_chain(retriever, llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98f3adb3-8917-44cd-badb-0b6647905f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/transformers/utils/import_utils.py:653: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/transformers/modeling_attn_mask_utils.py:448: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  or (hasattr(torch, \"_dynamo\") and torch._dynamo.is_compiling())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, the gradient (da and db) is calculated using the script\n",
      "`find_derivatives(X, y, z)`.  The script calculates the derivative of the cost function with respect\n",
      "to the input variables a and b as follows:  1. Calculate the error dz between the predicted values z\n",
      "and the actual values y. 2. Calculate the derivative da by taking the dot product of the transpose\n",
      "of X (X.T) and dz. 3. Calculate the derivative db by summing up the elements of dz.  The resultant\n",
      "derivatives da and db are then returned to the calling function.\n"
     ]
    }
   ],
   "source": [
    "get_response(\"How is gradient calculated?\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dca3fda-4db1-4fbb-a1f0-ada1eca36416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "type query here.....>>>>> hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/transformers/utils/import_utils.py:653: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/transformers/modeling_attn_mask_utils.py:448: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  or (hasattr(torch, \"_dynamo\") and torch._dynamo.is_compiling())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! It seems you're starting a conversation. I'm here to help with any questions or topics you'd\n",
      "like to discuss. What's on your mind?\n",
      " ### RESPONSE ###  None\n",
      "TIME TAKEN :::  3.8132479190826416\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "type query here.....>>>>> Explain me Backpropogation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/transformers/utils/import_utils.py:653: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/transformers/modeling_attn_mask_utils.py:448: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  or (hasattr(torch, \"_dynamo\") and torch._dynamo.is_compiling())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backpropagation!  In our context, backpropagation is used to minimize the overall loss (cost) by\n",
      "finding the optimum values of weights. The cost function we're using is the mean squared error\n",
      "(MSE), which represents the difference between the predicted output (`ao`) and the actual output\n",
      "(`y`).  The backpropagation process consists of two phases:  **Phase 1:**  * Calculate `dcost_dao`,\n",
      "the derivative of the total cost with respect to the output (`ao`). This is done using the formula\n",
      "`(1/m) * (ao - y)`. * Calculate `dao_dzo`, the derivative of `ao` with respect to `zo`. This is done\n",
      "using the sigmoid derivative function. * Calculate `dzo_dwo`, the derivative of `zo` with respect to\n",
      "the output weights (`w`). This is simply the transpose of the hidden layer activations (`ah.T`). *\n",
      "Calculate `dcost_dwo`, the derivative of the total cost with respect to the output weights (`w`).\n",
      "This is done by multiplying `dcost_dao`, `dao_dzo`, and `dzo_dwo`.  **Phase 2:**  * Calculate\n",
      "`dcost_dzo`, the derivative of the total cost with respect to the hidden layer activations (`zo`).\n",
      "This is simply `dcost_dao * dao_dzo`. * Calculate `dzo_dah`, the derivative of `zo` with respect to\n",
      "the hidden layer activations (`ah`). This is simply the transpose of the output weights (`w[1].T`).\n",
      "* Calculate `dcost_dah`, the derivative of the total cost with respect to the hidden layer\n",
      "activations (`ah`). This is done by multiplying `dcost_dzo` and `dzo_dah`.  These derivatives are\n",
      "used to update the weights and biases in our neural network, allowing us to minimize the loss\n",
      "function and improve the model's performance.\n",
      " ### RESPONSE ###  None\n",
      "TIME TAKEN :::  28.882346868515015\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "type query here.....>>>>> python code for binary search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/transformers/utils/import_utils.py:653: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/transformers/modeling_attn_mask_utils.py:448: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  or (hasattr(torch, \"_dynamo\") and torch._dynamo.is_compiling())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know. The provided context does not contain any information about binary search, which is a\n",
      "specific algorithm used to find an element in a sorted array. If you're looking for Python code for\n",
      "binary search, I'd be happy to help you with that! However, please provide more context or clarify\n",
      "what you mean by \"binary search\" so I can better assist you.\n",
      " ### RESPONSE ###  None\n",
      "TIME TAKEN :::  8.128325700759888\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype query here.....>>>>>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m     response \u001b[38;5;241m=\u001b[39m get_response(query, chain)\n",
      "File \u001b[0;32m~/work/env/dev/lib/python3.9/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/env/dev/lib/python3.9/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import time\n",
    "while True:\n",
    "    query = input(\"type query here.....>>>>>\")\n",
    "    start = time.time()\n",
    "    response = get_response(query, chain)\n",
    "    end = time.time()\n",
    "\n",
    "    print(\" ### RESPONSE ### \", response)\n",
    "    print(\"TIME TAKEN ::: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a947aad8-2755-4838-ae32-5094cd38a82a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
